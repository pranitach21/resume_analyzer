{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940db146-b5e3-4cfe-b93b-98cb99a88add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume_analyzer.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import docx\n",
    "import nltk\n",
    "import io\n",
    "import random\n",
    "import hashlib\n",
    "import requests\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from Courses import (\n",
    "    ds_course, web_course, android_course, \n",
    "    ios_course, uiux_course, resume_videos, interview_videos\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "SERPAPI_KEY = \"your_api_key_here\"  # Get from https://serpapi.com/\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "COURSE_CATEGORIES = {\n",
    "    'Data Science': {'courses': ds_course, 'keywords': ['data', 'python', 'machine learning']},\n",
    "    'Web Development': {'courses': web_course, 'keywords': ['web', 'javascript', 'react']},\n",
    "    'Android Development': {'courses': android_course, 'keywords': ['android', 'kotlin', 'mobile']},\n",
    "    'iOS Development': {'courses': ios_course, 'keywords': ['ios', 'swift', 'xcode']},\n",
    "    'UI/UX Design': {'courses': uiux_course, 'keywords': ['ui', 'ux', 'adobe', 'figma']}\n",
    "}\n",
    "\n",
    "def extract_text(file):\n",
    "    try:\n",
    "        if not file: return None\n",
    "        if file.name.endswith('.pdf'):\n",
    "            with pdfplumber.open(io.BytesIO(file.read())) as pdf:\n",
    "                return \"\\n\".join([page.extract_text() for page in pdf.pages])\n",
    "        elif file.name.endswith('.docx'):\n",
    "            doc = docx.Document(io.BytesIO(file.read()))\n",
    "            return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        st.error(f\"File error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def analyze_resume(jd_text, resume_text):\n",
    "    if not resume_text: return None\n",
    "    try:\n",
    "        stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        similarity_score = 0  # Initialize similarity score\n",
    "        \n",
    "        # Extract position and skills using regex\n",
    "        position_match = re.search(r'(?i)\\b(?:Senior|Junior)?\\s*(.*?Developer|Data Scientist|UI Designer|Engineer)\\b', resume_text)\n",
    "        skills_match = re.search(r'(?i)Skills:?\\s*([\\w\\s,]+)(?:\\n|$)', resume_text)\n",
    "        \n",
    "        custom_keywords = []\n",
    "        position = \"Professional\"\n",
    "        if position_match:\n",
    "            position = position_match.group(1).strip()\n",
    "            custom_keywords.extend(position.lower().split())\n",
    "        \n",
    "        if skills_match:\n",
    "            skills = skills_match.group(1).replace(',', ' ').split()\n",
    "            custom_keywords.extend([s.lower() for s in skills if len(s) > 2])\n",
    "\n",
    "        # Extract TF-IDF keywords and calculate similarity\n",
    "        documents = []\n",
    "        if jd_text:\n",
    "            documents.append(' '.join([w for w in nltk.word_tokenize(jd_text.lower()) \n",
    "                                     if w.isalpha() and w not in stop_words]))\n",
    "        \n",
    "        documents.append(' '.join([w for w in nltk.word_tokenize(resume_text.lower()) \n",
    "                                 if w.isalpha() and w not in stop_words]))\n",
    "        \n",
    "        vectors = vectorizer.fit_transform(documents)\n",
    "        \n",
    "        # Calculate similarity score if JD exists\n",
    "        if jd_text:\n",
    "            similarity_score = round(cosine_similarity(vectors[0], vectors[1])[0][0] * 100, 2)\n",
    "\n",
    "        tfidf_keywords = list(vectorizer.get_feature_names_out())\n",
    "        \n",
    "        # Combine and prioritize keywords\n",
    "        combined_keywords = list(set(custom_keywords + tfidf_keywords))\n",
    "        priority_terms = ['developer', 'scientist', 'engineer', 'designer', 'android', \n",
    "                         'ios', 'data', 'machine', 'ux', 'ui', 'mobile']\n",
    "        \n",
    "        sorted_keywords = sorted(combined_keywords,\n",
    "                               key=lambda x: (x in priority_terms, x in custom_keywords),\n",
    "                               reverse=True)[:15]\n",
    "\n",
    "        return {\n",
    "            'similarity_score': similarity_score,  # Now included in response\n",
    "            'position': position,\n",
    "            'keywords': sorted_keywords,\n",
    "            'skills': custom_keywords,\n",
    "            'unique_id': hashlib.sha256(resume_text.encode()).hexdigest()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        st.error(f\"Analysis failed: {str(e)}\")\n",
    "        return None\n",
    "        \n",
    "def get_linkedin_jobs(position, keywords, upload_date):\n",
    "    try:\n",
    "        if not position or not keywords:\n",
    "            return []\n",
    "        \n",
    "        # Clean and format position title\n",
    "        clean_position = re.sub(r'[^a-zA-Z\\s]', '', position).strip().title()\n",
    "        \n",
    "        # Calculate exact 7-day window\n",
    "        end_date = upload_date.strftime(\"%Y%m%d\")\n",
    "        start_date = (upload_date - timedelta(days=7)).strftime(\"%Y%m%d\")\n",
    "        \n",
    "        # Build position-specific query\n",
    "        params = {\n",
    "            \"engine\": \"linkedin_jobs\",\n",
    "            \"q\": f'\"{clean_position}\"',\n",
    "            \"keywords\": \" \".join(keywords[:5]),\n",
    "            \"location\": \"worldwide\",\n",
    "            \"sort_by\": \"date\",\n",
    "            \"api_key\": SERPAPI_KEY,\n",
    "            \"date_posted\": f\"{start_date}-{end_date}\",\n",
    "            \"chips\": f\"date_posted_range:{start_date}-{end_date}\"\n",
    "        }\n",
    "\n",
    "        response = requests.get(\"https://serpapi.com/search\", params=params)\n",
    "        jobs = response.json().get(\"jobs\", [])[:5]\n",
    "        \n",
    "        return [{\n",
    "            \"title\": job.get(\"title\"),\n",
    "            \"company\": job.get(\"company\"),\n",
    "            \"url\": job.get(\"link\"),\n",
    "            \"posted_date\": job.get(\"posted_date\"),\n",
    "        } for job in jobs if job.get(\"posted_date\")]\n",
    "    except Exception as e:\n",
    "        st.error(f\"Failed to fetch jobs: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def show_job_recommendations(position, keywords, upload_date):\n",
    "    with st.expander(\"üîç Searchh Job Openings \", expanded=True):\n",
    "        if not position or not keywords:\n",
    "            st.warning(\"No position or keywords extracted from resume\")\n",
    "            return\n",
    "            \n",
    "        jobs = get_linkedin_jobs(position, keywords, upload_date)\n",
    "        \n",
    "        if not jobs:\n",
    "            #st.info(\"No recent job openings matching your profile\")\n",
    "            st.markdown(\n",
    "                f\"\"\"<a href=\"https://www.linkedin.com/jobs/search/?keywords={position}\" \n",
    "                target=\"_blank\" style=\"color: #0077b5; text-decoration: none;\">\n",
    "                ‚û§ Search {position} jobs on LinkedIn </a>\"\"\",\n",
    "                unsafe_allow_html=True\n",
    "            )\n",
    "            return\n",
    "        \n",
    "        for job in jobs:\n",
    "            try:\n",
    "                post_date = datetime.strptime(job['posted_date'], \"%Y-%m-%d\")\n",
    "                days_old = (upload_date - post_date).days\n",
    "                \n",
    "                st.markdown(f\"\"\"\n",
    "                <div style=\"padding:10px; margin:10px 0; border:1px solid #e0e0e0; border-radius:5px;\">\n",
    "                    <h4 style=\"margin:0; color:#1a0dab;\">{job['title']}</h4>\n",
    "                    <p style=\"margin:0.5em 0; color:#666; font-size:0.9em;\">\n",
    "                        {job['company']}\n",
    "                    </p>\n",
    "                    <p style=\"margin:0.5em 0; font-size:0.9em;\">\n",
    "                        <a href=\"{job['url']}\" target=\"_blank\" \n",
    "                        style=\"color:#0077b5; text-decoration:none;\">\n",
    "                            ‚û§ View on LinkedIn ‚Ä¢ Posted {days_old} days ago\n",
    "                        </a>\n",
    "                    </p>\n",
    "                </div>\n",
    "                \"\"\", unsafe_allow_html=True)\n",
    "            except Exception as e:\n",
    "                st.error(f\"Error showing job: {str(e)}\")\n",
    "                \n",
    "def hr_dashboard():\n",
    "    st.title(\"HR Resume Analyzer\")\n",
    "    uploaded_file = st.file_uploader(\"Upload Candidate Resume\", type=[\"pdf\", \"docx\"])\n",
    "    jd_text = st.text_area(\"Paste Job Description\", height=200)\n",
    "    \n",
    "    if st.button(\"Analyze Resume\"):\n",
    "        if not uploaded_file or not jd_text:\n",
    "            st.error(\"Please upload resume and enter job description\")\n",
    "            return\n",
    "            \n",
    "        resume_text = extract_text(uploaded_file)\n",
    "        if resume_text:\n",
    "            analysis = analyze_resume(jd_text, resume_text)\n",
    "            if analysis:\n",
    "                st.subheader(\"Analysis Results\")\n",
    "                \n",
    "                # Check if similarity_score exists before displaying\n",
    "                if 'similarity_score' in analysis:\n",
    "                    st.metric(\"JD Match Score\", f\"{analysis['similarity_score']}%\")\n",
    "                else:\n",
    "                    st.warning(\"Similarity score not available\")\n",
    "                \n",
    "                with st.expander(\"üîç Key Insights\", expanded=True):\n",
    "                    st.metric(\"Position Match\", analysis.get('position', 'Not detected'))\n",
    "                    st.write(\"**Top Keywords:**\", \", \".join(analysis.get('keywords', [])[:10]))\n",
    "                \n",
    "                with st.expander(\"üìä Detailed Analysis\"):\n",
    "                    st.write(\"**All Identified Skills:**\", \", \".join(analysis.get('skills', [])))\n",
    "\n",
    "def user_dashboard():\n",
    "    st.title(\"Job Seeker Dashboard\")\n",
    "    uploaded_file = st.file_uploader(\"Upload Your Resume\", type=[\"pdf\", \"docx\"])\n",
    "    \n",
    "    if uploaded_file:\n",
    "        upload_date = datetime.now()\n",
    "        resume_text = extract_text(uploaded_file)\n",
    "        if resume_text:\n",
    "            analysis = analyze_resume(\"\", resume_text)\n",
    "            if analysis:\n",
    "                with st.expander(\"üìä Resume Analysis\", expanded=True):\n",
    "                    st.markdown(f\"**Current Position:** {analysis['position']}\")\n",
    "                    st.write(\"**Key Skills:**\", \", \".join(analysis['skills'][:10]))\n",
    "                \n",
    "                show_job_recommendations(analysis['position'], analysis['keywords'], upload_date)\n",
    "                \n",
    "                with st.expander(\"üéì Recommended Courses\", expanded=True):\n",
    "                    categories_shown = 0\n",
    "                    for category, data in COURSE_CATEGORIES.items():\n",
    "                        if set(analysis['keywords']).intersection(data['keywords']):\n",
    "                            st.markdown(f\"**{category}**\")\n",
    "                            for course in random.sample(data['courses'], 3):\n",
    "                                st.markdown(f\"- [{course[0]}]({course[1]})\")\n",
    "                            categories_shown += 1\n",
    "                    \n",
    "                    if categories_shown == 0:\n",
    "                        st.markdown(\"**General Career Development**\")\n",
    "                        for course in random.sample(web_course + ds_course, 5):\n",
    "                            st.markdown(f\"- [{course[0]}]({course[1]})\")\n",
    "                \n",
    "                with st.expander(\"üìù Interview Preparation\", expanded=True):\n",
    "                    col1, col2 = st.columns(2)\n",
    "                    with col1:\n",
    "                        st.markdown(\"#### Resume Building\")\n",
    "                        st.video(random.choice(resume_videos))\n",
    "                    with col2:\n",
    "                        st.markdown(\"#### Interview Techniques\")\n",
    "                        st.video(random.choice(interview_videos))\n",
    "\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"Resume Analyzer\", layout=\"wide\")\n",
    "    \n",
    "    if 'logged_in' not in st.session_state:\n",
    "        st.session_state.update(logged_in=False, role=None)\n",
    "    \n",
    "    if not st.session_state.logged_in:\n",
    "        st.title(\"Career Portal Login\")\n",
    "        with st.form(\"login_form\"):\n",
    "            username = st.text_input(\"Username\")\n",
    "            password = st.text_input(\"Password\", type=\"password\")\n",
    "            if st.form_submit_button(\"Login\"):\n",
    "                try:\n",
    "                    df = pd.read_excel('users.xlsx')\n",
    "                    valid_user = not df[(df['Username'] == username) & (df['Password'] == password)].empty\n",
    "                    \n",
    "                    if valid_user:\n",
    "                        if username.startswith(\"hr_\"):\n",
    "                            st.session_state.update(logged_in=True, role=\"hr\")\n",
    "                        elif username.startswith(\"user_\"):\n",
    "                            st.session_state.update(logged_in=True, role=\"user\")\n",
    "                        st.rerun()\n",
    "                    else:\n",
    "                        st.error(\"Invalid credentials\")\n",
    "                except FileNotFoundError:\n",
    "                    st.error(\"User database not found\")\n",
    "    else:\n",
    "        if st.sidebar.button(\"Logout\"):\n",
    "            st.session_state.clear()\n",
    "            st.rerun()\n",
    "        \n",
    "        if st.session_state.role == \"hr\":\n",
    "            hr_dashboard()\n",
    "        else:\n",
    "            user_dashboard()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
